# 🕷️ 爬虫 2.0（添加分类功能）工作流说明文档

本文档对应工作流文件：`01-爬虫2.0-添加分类功能.json`

---

## 1. 工作流概述（做什么）

该工作流通过 Chat 触发方式接收一个站点的入口地址（通常是 sitemap.xml 或页面 URL），按站点规则筛选与分类 URL，批量抓取网页 HTML 内容，提取关键信息并进行结构化处理：
- 以正则与简单清洗手段提取 `<head>` SEO 相关标签与正文区域内容
- 通过大模型（Google Gemini）对内容进行结构化整理（面向 RAG 知识库）
- 生成稳定页级指纹（`docId`）并在 Pinecone 中“先删后写”，实现去重与增量更新
- 将结构化文本存入 Google Drive 指定文件夹
- 将内容切分后生成向量并写入 Pinecone 指定 Index

支持多站点（如 nearstream / nearhub）分支处理与不同的存储配置（Drive 目录、Pinecone 索引）。

---

## 2. 前置准备（需要什么）

- n8n 版本：建议 v1.94.0 及以上
- 启用 AI
- 可用的外部服务/凭证：
  - Google Gemini(PaLM) API Key（用于 AI Agent 与 Embeddings）
  - Google Drive OAuth2（用于创建文件）
  - Pinecone API Key 与 Index（用于向量存储）
  - 可访问的爬虫服务 API：`http://49.51.248.71:11235/crawl`

> 建议：将所有密钥迁移到 n8n 凭证管理中，避免硬编码在节点参数内。

---

## 3. 核心数据流与节点说明（怎么做）

下述按两条主分支概述（网站一 / 网站二）。两条分支流程相同，仅目标配置（Drive 文件夹、Pinecone 索引）不同。

### 3.1 触发与 URL 源获取
- `When chat message received`（Chat Trigger）
  - 接收聊天输入 `chatInput`（通常为 sitemap 或入口 URL）。
- `HTTP Request1` + `XML1`
  - 读取 `chatInput` 指向的 XML（sitemap），解析为可遍历结构。
- `Switch2`
  - 根据 `chatInput` 内容判断站点（关键字包含 `网站一的关键词` 或 `网站二的关键词`），分流到对应分支。

### 3.2 URL 过滤与批处理（以 网站一 分支为例）
- `Filter1` / `Code2` / `统一split-out接受名称1`
  - 从 `urlset.url` 中筛选目标 URL 集合；
  - 设置该分支使用的 Google Drive 目标文件夹 `id` 与 Pinecone 索引名 `vector`；
  - 输出 `{ urls, id, vector }`。
- `Split Out1`（fieldToSplitOut = urls）+ `Limit1`（控制本次最大处理数）+ `Loop Over Items1`（batchSize=3）
  - 将 URL 列表拆分并按批次处理，避免一次性拉满。

### 3.3 抓取与内容解析
- `HTTP Request7`（POST 到爬虫服务 `/crawl`）
  - 提交单条 URL 进行抓取，返回 `{ results: [{ url, html }] }`。
- `Wait`（可控节流）
  - 控制抓取节奏，降低被目标站限流的风险。
- `HTML1`（extractHtmlContent）
  - 从 `results[0].html` 提取：
    - `head`：完整 `<head>` 片段
    - `content`：`#website-content` 选择器对应的正文区域
- `Code1`
  - 纯字符串正则方式：
    - 保留 SEO 关键标签（title/meta/部分 link/canonical/JSON-LD）
    - 正文标签做“去属性”清洗（保留 `<img>`）
  - 计算文件名：基于 URL path 推导 `name`
  - 输出 `{ data, url, name }`

### 3.4 去重与增量（稳定页级 ID）
- `Build Doc Fingerprint1`
  - 规范化 URL（去 hash、去尾斜杠、移除 UTM 参数等）
  - 使用 FNV-1a 64 位哈希得到 `docId`（字符串）
- `HTTP Request5`（Pinecone 删除旧向量）
  - `POST /vectors/delete`，以 filter `{ doc_id: docId }` 全量删除旧版本向量；
  - 节点 `onError: continueRegularOutput`，删除失败不中断，便于幂等与覆盖写入。

### 3.5 LLM 结构化与落盘
- `AI Agent1`（Google Gemini Chat Model1 作为子模型）
  - Prompt：将 HTML 清洗后的内容整理为适合 RAG 的结构化文本（标题分层、FAQ、可检索分块等）。
- `Search Google Drive for File-nearstream1` → `If1` → `Create file from text1`
  - 在对应的 Drive 文件夹中查询同名文件（`name + .txt`）；
  - 若不存在则创建文件并写入 LLM 整理后的内容；存在时可按需扩展 Update 流程（当前示例为新增）。

### 3.6 切分与向量化（写入 Pinecone）
- `Convert to File` / `Default Data Loader1` / `Recursive Character Text Splitter1`
  - 将文本按块切分（chunkOverlap=100 等），准备嵌入。
- `Embeddings Google Gemini1` → `Pinecone Vector Store1`
  - 计算嵌入并写入目标 Index（通过前文分支传入的 `vector` 值），同时附带元数据（`product_name`、`product_url` 等）。

> 网站一 主线的镜像流程在另一分支（`Switch`/`Filter`/`统一split-out接受名称` 等）中同理存在。

---

## 4. 关键参数与可配置项（改哪里）

- 分站点关键字匹配：`Switch` / `Switch2` 中的 `contains` 条件（`nearstream` / `nearhub`）
- URL 筛选规则：`Filter` / `Filter1` 里 `productsName`、`domain`、各类路径前缀判定（blog/solutions/help-center/compare 等）
- 抓取服务地址：`HTTP Request6/7` 的 `url`（`/crawl` API）
- 正文 CSS 选择器：`HTML/HTML1` 的 `dataPropertyName` 与 `extractionValues`（`#website-content`）
- LLM Prompt：`AI Agent/AI Agent1` 的 `text`（结构化规范、语言、FAQ 输出等）
- Drive 目标文件夹：`Search Google Drive for File-*` 与 `Create file from text*` 里父目录 ID（分站点）
- Pinecone 索引名：`Code2` / `统一split-out接受名称1` 里输出的 `vector`；以及向量写入节点 `Pinecone Vector Store*`
- 批处理与节流：`Limit*`（maxItems）、`Loop Over Items*`（batchSize）、`Wait/Wait1`（秒数）

---

## 5. 运行步骤（如何用）

1) 打开工作流，并确保以下凭证可用：
   - Google Gemini(PaLM) API、Google Drive OAuth2、Pinecone API
2) 在编辑器的 Chat 面板或支持 Chat Trigger 的 UI 中，输入 sitemap 或入口 URL（如 `https://example.com/sitemap.xml`）
3) 观察执行：
   - XML 解析 → 站点分流 → URL 批处理 → 爬虫抓取 → HTML 提取 → 清洗 & 指纹 → Pinecone 删除旧向量 → LLM 整理 → Drive 落盘 → 切分与向量化入库
4) 在 Drive 对应目录查看生成的 `.txt` 文件；在 Pinecone 控制台查看向量写入结果。

---

## 6. 错误处理与速率控制（更稳）

- 删除旧向量：`HTTP Request4/5` 设为 `onError: continue`，删除失败不影响后续写入（方便覆盖式更新）
- 抓取速率：使用 `Wait/Wait1` 与 `Loop Over Items*` 的 `batchSize` 控制并发与频率
- 建议为关键 HTTP 节点开启重试（Options）与超时，避免短暂网络抖动导致失败
- 建议为 LLM 节点设置失败兜底（如 `Continue On Fail` + 分支吸收），并在日志中记录失败样本

---

## 7. 安全与合规（更安全）

- 将 Pinecone API Key、Google API 凭证全部迁移至 n8n 凭证体系，避免明文硬编码
- 限制外部爬虫服务访问权限，仅允许内网或受控源调用
- 对于 Drive 与 Pinecone 的目标资源，按最小权限授予

---

## 8. 常见问题（FAQ）

- Q：为什么要“先删后写”Pinecone 向量？
  - A：同一 `docId` 的旧版本向量会残留，先删可确保索引数据一致（去重+增量）。

- Q：Drive 文件已存在怎么办？
  - A：当前示例是新增写入。若需“存在则覆盖/更新”，可在 `If*` 分支中补充 Update File 逻辑。

- Q：抓取不到正文怎么办？
  - A：检查 `HTML/HTML1` 的 CSS 选择器（`#website-content`）是否适配该站点；或扩展解析规则。

- Q：多站点如何继续扩展？
  - A：在 `Switch*` 中新增分支，并为分支配置专属 `id`（Drive 目录）与 `vector`（Pinecone 索引）。

---

## 9. 变更建议（可选优化）

- 将所有硬编码的 Index 名、目录 ID、API Key 抽取为环境变量或 n8n 变量节点
- 为 HTTP Request 节点配置重试与指数退避；为 LLM 节点设置最大运行时与超时
- 增加“结果落库”（如 Notion/数据库）与“告警通知”（如 Telegram/Email）
- 增加“失败样本回收站”（存储到 Drive 的 error 文件夹）以便回溯

---。
