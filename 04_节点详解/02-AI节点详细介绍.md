# 🌟 AI 节点详细介绍

n8n 内置了可视化的 LangChain 节点，帮助我们快速接入与使用不同的 LLM 模型，搭建多类型 AI 能力。在熟悉 n8n 的 AI 节点之前，先完成一些必要的科普，再循序讲解核心节点与常见场景。

---

## 0. 大模型 AI 接入 n8n 的科普

### 0.1 什么是大语言模型（LLM）？
大语言模型是一类深度学习模型，目标是理解与生成人类语言。它通过海量文本语料学习语言模式，并据此完成续写、问答、摘要、分类、纠错、情感分析、代码生成等任务。

> 例：输入一个问题，模型生成答案；输入一段材料，模型生成摘要；输入自然语言，模型输出可运行的代码等。

### 0.2 仅有 ChatGPT Plus 账号是否足够？
不够。ChatGPT（产品）与 GPT-4/Claude/Gemini 等 API（面向程序的接口）是两件事。n8n 作为自动化程序，需要对接各家模型的开发者 API。你需要：
- 能访问海外互联网（ChatGPT Plus 账号通常意味着你已具备条件）
- 申请各模型提供商的开发者账号与 API Key（OpenAI、Google、Anthropic 等）

> 出于合规考虑，本教程不提供具体的开发者账号注册指南。

### 0.3 什么是 LangChain？
LangChain 是一个为大语言模型应用而生的中间层/编排框架，统一了不同模型与工具的接口，降低切换成本与组合复杂度。n8n 将 LangChain 封装为一组可视化节点，让我们在编辑画布上即可完成：
- 选择/切换不同模型
- 增加 Memory（记忆）
- 连接工具（Tools）
- 串联多步推理流程

---

## 1. 节点概览（Advanced AI 分类）

Advanced AI 分类下包含多种 AI 节点与模板。核心理念：以“链（Chain）”为载体连接模型、记忆、工具与外部数据。

本文重点讲解两类高频节点：
- Basic LLM Chain（基础链）：最简单、最通用的 LLM 调用节点
- AI Agent（智能体）：在基础链之上引入 Memory、Tool 等组件的进阶能力

> 你也可以从 AI Templates 导入官方社区模板，快速获得可运行的链路示例。

---

## 2. Basic LLM Chain

Basic LLM Chain 是对接语言模型的“基础工作马”。不强调对话记忆与复杂工具链，适合一次性处理类任务：摘要、分类、纠错、抽取、改写、要点提取等。

流程简述：
1) 从上游获取数据 → 2) 结合 Prompt → 3) 调用 LLM API → 4) 输出结果

### 2.1 关键参数说明

- 必填 Prompt（提示词来源）
  - Take from previous node automatically：自动取上游最近的聊天消息（通常来自 Chat Trigger）。若你的 Prompt 并非来自 Chat Trigger，建议选择下方的 Define below。
  - Define below：在本节点中直接编写 Prompt 文本。

- 必填 Text（当 Prompt=Define below 时出现）
  输入你希望模型处理的具体内容，可与上游变量结合：
  ```
  请为以下文章生成 5 个备选标题：
  {{ $json.text }}
  ```
  其中 `{{$json.text}}` 为上游传入的正文。

- 可选 Require Specific Output Format（约束输出格式）
  启用后可要求模型以严格的结构输出（如 JSON schema），便于后续节点解析。

- 可选 Chat Messages（当使用 Chat 类模型时）
  预置多轮对话上下文（角色、类型、消息内容），增强语境一致性。适合对话型应用或需要少量上下文记忆的场景。

- 必填 Model（模型子节点）
  Basic LLM Chain 需要你在画布上添加一个“Model 子节点”，用于实际连接具体模型供应商。

### 2.2 可选模型（子节点）

常见可用类型（随版本更新可能变动）：
- OpenAI Chat Model / OpenAI Model / Azure OpenAI Model
- Google PaLM Chat Model / Google Gemini Chat Model
- Anthropic Chat Model（Claude）
- Cohere Model
- Mistral Cloud Chat Model
- Groq Chat Model
- AWS Bedrock Chat Model
- Hugging Face Inference Model
- Ollama Chat Model / Ollama Model（本地/私有化）

> 各模型子节点的具体参数略有差异，可在子节点面板中点击跳转至官方文档查看。

---

## 3. AI Agent（进阶）

AI Agent 可以视为 Basic LLM Chain 的“扩展版”：
- 通过内部参数选择 Agent 类型（任务模式）
- 可挂载 Memory（记忆）与 Tool（工具）子节点
- 支持更复杂的推理链与工具调用

### 3.1 Agent 参数（任务模式）

不同 Agent 类型对应不同用途与可用卡槽：

| Agent 类型 | 可用卡槽 | 适用说明 |
|---|---|---|
| Conversational Agent | Memory / Tool | 面向多轮对话；在 Basic LLM Chain 基础上增加记忆与工具 |
| Tools Agent | Memory / Tool | 自然语言操作一个或多个工具（不强调长期记忆） |
| OpenAI Functions Agent | Memory / Tool | 面向 Function Call 的工作流（结构化调用） |
| Plan and Execute Agent | Tool | 规划-执行范式：AI 自主规划与串联工具 |
| ReAct Agent | Memory / Tool | 观察-行动-反思范式，多步调用与校验，效果强但可能多次请求 |
| SQL Agent | Memory | 对数据库进行自然语言查询与读写 |

> 不同 Agent 的必填项略有不同，请在节点参数面板或官方文档中查看。

### 3.2 Memory 子节点（可选）

为 Agent 提供短期/长期记忆能力：
- Window Buffer Memory：浏览器窗口级短期记忆，免部署，但刷新即失。
- Redis Chat Memory：将对话存入 Redis，支持在刷新后找回，但通常为短期缓存。
- Motorhead：开源记忆服务，支持存储、向量化与检索。
- Xata / Zep：第三方长期记忆/向量数据库服务（免部署，付费/商用）。


### 3.3 Tool 子节点（可选）

让 Agent 在语言之外“动手做事”，例如：
- Calculator：可靠数值计算
- Custom Code Tool：自定义 JS/Python 逻辑
- SerpAPI：联网搜索检索资料
- Wikipedia：百科检索
- Wolfram Alpha：计算/可视化/学术问答
- Custom n8n Workflow Tool：把另一个 Workflow 变成可调用的“工具”

> 对中国用户而言，Custom n8n Workflow Tool 非常实用：可以把你为国内服务（如飞书、企微、百度搜索等）编写的工作流包装为 Tool，从而让 AI Agent 间接调用国内生态。

---

## 4. 发散与模板

- 除本文两大核心节点外，Advanced AI 下还有 OpenAI 专项节点（绘图、文件上传等）与 Question and Answer Chain（针对私有知识库问答）等。
- 逻辑共性：输入数据 → 规定 AI 行为（Prompt/Agent）→（可选）记忆/工具 → 获取结构化结果。
- 模板市场：节点面板 Advanced AI > AI Templates 可一键导入社区示例，便于学习与复用。
- 若内置节点无法完全覆盖你的需求，可使用“LangChain Code”节点直接编写链式逻辑。

---

## 5. 实战建议（速查）

- 小任务优先 Basic LLM Chain；需要多轮对话/工具调用再上 AI Agent
- Prompt 可模板化并结合上游变量；对结构化输出使用“Require Specific Output Format”
- 频繁调用第三方服务时，注意速率限制与重试策略（Wait、Error Trigger）
- 本地/私有化优先考虑 Ollama；合规与成本优先时可选代理商（如 CloseAI/WildCard 等）

---

> 提示：若运行环境无法访问 OpenAI/Google，可使用兼容代理服务；如需国内生态集成，建议将现有 Workflow 封装为 Tool 供 Agent 调用。
